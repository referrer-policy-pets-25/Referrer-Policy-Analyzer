{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leak Detector\n",
    "\n",
    "Check possible data leaks on three vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import os\n",
    "\n",
    "from helpers.utils import (\n",
    "    leaky\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = '../output/data_raw/2025-02-08_noAct_raw.parquet'\n",
    "# folder_path = '../output/data_raw/2024-01-24_SF_raw.parquet'\n",
    "# folder_path = '../output/data_raw/2024-01-24_SG_raw.parquet'\n",
    "folder_path = '../output/data_raw/2024-01-24_AMS_raw.parquet'\n",
    "df = pd.read_parquet(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-24\n",
      "Type: SG\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "match = re.search(r'(\\d{4}-\\d{2}-\\d{2})_([^_]+)', folder_path)\n",
    "if match:\n",
    "    extract_date, extract_type = match.groups()\n",
    "    print(\"Date:\", extract_date)\n",
    "    print(\"Type:\", extract_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leak Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run leak detector and put it into the colomn in dataframe\n",
    "\n",
    "df[['url_leaks',\n",
    "            'post_leaks',\n",
    "            'referer_leaks']]= df.parallel_apply(\n",
    "    leaky, axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the leaks and put it into a new colomn in dataframe \n",
    "# use parallel apply to speed up the process\n",
    "\n",
    "df['leaks'] = df.parallel_apply(\n",
    "    lambda row: ' - '.join(\n",
    "        [col for col in [\n",
    "            'url_leaks', \n",
    "            'post_leaks', \n",
    "            'referer_leaks'] \n",
    "            if row[col] not in [None, '[]', 'None' ]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the rows with no leaks\n",
    "df = df[df['leaks'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../output/data_leaks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../output/data_leaks/\"+extract_date+\"_\"+extract_type+'_leaks.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
